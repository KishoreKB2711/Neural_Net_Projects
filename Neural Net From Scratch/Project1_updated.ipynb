{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 - Neural Network From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_set(num):\n",
    "    np.random.seed(7)\n",
    "    training_set = []\n",
    "    for i in range(num):\n",
    "       x = np.random.rand()\n",
    "       y = np.random.rand()\n",
    "       z = x * y\n",
    "\n",
    "       training_set.append([x,y,z])  \n",
    "\n",
    "    return training_set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    params = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        params['W'+str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        params['b'+str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function\n",
    "def sigmoid(x):\n",
    "    return(1/(1 + np.exp(-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_forward(x, w1, w2, w3):\n",
    "    # hidden\n",
    "    z1 = x.dot(w1)# input from layer 1\n",
    "    a1 = sigmoid(z1)# out put of layer 2\n",
    "    \n",
    "    # hidden\n",
    "    z2 = a1.dot(w2)# input from layer 2\n",
    "    a2 = sigmoid(z2)# out put of layer 3\n",
    "     \n",
    "    # Output layer\n",
    "    z3 = a2.dot(w3)# input of out layer\n",
    "    a3 = sigmoid(z3)# output of out layer\n",
    "    return(a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the weights randomly\n",
    "def generate_wt(x, y):\n",
    "    l =[]\n",
    "    for i in range(x * y):\n",
    "        l.append(np.random.randn())\n",
    "    return(np.array(l).reshape(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loss we will be using mean square error(MSE)\n",
    "def loss(out, Y):\n",
    "    s =(np.square(out-Y))\n",
    "    s = np.sum(s)/len(Y)\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(x, y, w1, w2, w3, alpha):\n",
    "     \n",
    "    # hidden layer\n",
    "    z1 = x.dot(w1)# input from layer 1\n",
    "    a1 = sigmoid(z1)# output of layer 2\n",
    "\n",
    "    # hidden\n",
    "    z2 = a1.dot(w2)# input from layer 2\n",
    "    a2 = sigmoid(z2)# out put of layer 3\n",
    "     \n",
    "    # Output layer\n",
    "    z3 = a2.dot(w3)# input of out layer\n",
    "    a3 = sigmoid(z3)# output of out layer\n",
    "    # error in output layer\n",
    "    d3 =(a3-y)\n",
    "    # print(w3.shape, d3.shape, a2.shape, y.shape)\n",
    "    d2 = np.multiply((w3.dot((d3.transpose()))).transpose(),\n",
    "                                   (np.multiply(a2, 1-a2)))\n",
    "    d1 = np.multiply((w2.dot((d2.transpose()))).transpose(),\n",
    "                                   (np.multiply(a1, 1-a1)))\n",
    " \n",
    "    # print(x.shape, d1.shape)\n",
    "    x = np.expand_dims(x, 1)\n",
    "    d1 = np.expand_dims(d1, -1)\n",
    "    # print(x.shape, d1.shape)\n",
    "    # Gradient for w1, w2 and w3\n",
    "    w1_adj = x.dot(d1.transpose())\n",
    "    w2_adj = a1.transpose().dot(d2)\n",
    "\n",
    "    # print(a2.shape, d3.shape)\n",
    "    a2 = np.expand_dims(a2, -1)\n",
    "    d3 = np.expand_dims(d3, -1)\n",
    "    # print(a2.shape, d3.shape)\n",
    "    w3_adj = a2.dot(d3)\n",
    "     \n",
    "    # Updating parameters\n",
    "    w1 = w1-(alpha*(w1_adj))\n",
    "    w2 = w2-(alpha*(w2_adj))\n",
    "    w3 = w3-(alpha*(w3_adj))\n",
    "     \n",
    "    return(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, Y, w1, w2, w3, alpha = 0.01, epoch = 10):\n",
    "    acc =[]\n",
    "    losss =[]\n",
    "    for j in range(epoch):\n",
    "        l =[]\n",
    "        for i in range(len(x)):\n",
    "            out = f_forward(x[i], w1, w2, w3)\n",
    "            l.append((loss(out, Y[i])))\n",
    "            # print(x[i].shape, Y[i].shape)\n",
    "            w1, w2, w3 = back_prop(x[i], Y[i], w1, w2, w3, alpha)\n",
    "        print(\"epochs:\", j + 1, \"======== acc:\", (1-(sum(l)/len(x)))*100)  \n",
    "        acc.append((1-(sum(l)/len(x)))*100)\n",
    "        losss.append(sum(l)/len(x))\n",
    "    return(acc, losss, w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w1, w2, w3):\n",
    "    Out = f_forward(x, w1, w2, w3)\n",
    "    return Out \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train And Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(generate_training_set(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200 3200\n"
     ]
    }
   ],
   "source": [
    "x_train = training_set[0:3200 , 0:2]\n",
    "y_train = training_set[0:3200 , 2:3]\n",
    "\n",
    "print (len(x_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 800\n"
     ]
    }
   ],
   "source": [
    "x_test = training_set[3200:4000 , 0:2]\n",
    "y_test = training_set[3200:4000 , 2:3]\n",
    "\n",
    "print (len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.07157995  0.53004552 -0.40449156 -2.1257407   2.00411912  0.35951324\n",
      "   0.60949878  0.97439628 -0.0939196  -0.63160602  0.47130099  0.95789945\n",
      "   1.29206037 -1.22828592  0.96923046 -1.64451028  0.56822771 -0.5975909\n",
      "   0.69716244  0.83280882  0.51930993  0.90361698  0.79201289  0.1912749\n",
      "   1.42439391 -0.02575197 -0.57002125  0.24444262 -0.7174741   0.02432686\n",
      "   0.02269626  1.73772275  1.89703485 -1.32773938 -0.83782566  0.8651327\n",
      "   0.36308963  1.85040103  1.01380304 -0.08243479  2.77524301 -1.41901464\n",
      "   0.56407497  1.29879902  0.78509558 -0.64728639 -1.16121034  0.90325444\n",
      "  -0.20544373 -0.05395595  0.42491522 -0.0776579   1.60922065  1.4311266\n",
      "  -1.45030007  0.60215037 -0.05449171 -1.40786877  0.25183182  0.14457528\n",
      "  -0.76178562  0.39404104  1.43696993 -0.73277254 -1.10279678 -0.6355066\n",
      "   0.44428397  1.58936323 -0.67303273 -0.87052524 -0.82151879 -0.61292154\n",
      "   1.8113112   0.89987309 -2.45922506 -0.5502992   0.04204112 -0.83098105\n",
      "  -0.46656682 -0.45408338  0.28449279  1.53204264 -3.02569491  0.25970552\n",
      "   1.58365809  0.35046596 -0.08766747  0.56922767  1.04078576  1.04356298\n",
      "   0.56256734 -1.34670098  0.46232932  1.00209639 -0.91057275 -2.23621456\n",
      "   0.37671189  1.10163208 -1.29147366  0.85185158]\n",
      " [-0.95253951 -0.21211626  0.76691442 -1.23311242  0.50579007 -0.55355606\n",
      "   1.43439012 -0.43563374  0.14511147  0.34667548 -0.55166999 -0.10471967\n",
      "  -0.34797556  1.17107755 -0.62613116 -0.45975805 -0.67242935 -0.33664207\n",
      "   0.54310515 -0.23640453 -0.33373573 -0.59455018 -0.25950234  0.74436611\n",
      "  -0.38304589  1.01923808  2.22031287 -0.09898243  1.52417875 -1.43749863\n",
      "  -0.34054746  0.73245092  0.4961798  -0.84167921  0.74144016  2.68665184\n",
      "   0.75995455 -1.08923583 -0.79696637 -0.70309714  0.24090825  1.66458442\n",
      "   0.93514455  2.13192041  0.28917473  0.53623678  1.677349    0.12211641\n",
      "   1.60431629  1.32328494 -0.89342248 -0.2625346  -0.15773614 -0.26672366\n",
      "   0.27872487 -0.66881605  1.43847191  0.69059615  0.86661136  0.89989764\n",
      "  -1.09142705  0.89141471 -0.63830932  1.83937521 -1.45544673  1.21536225\n",
      "  -0.85548626  0.05206782  0.79216521 -1.07260834 -0.45442709  0.65837853\n",
      "  -1.35478041 -2.02805031  0.37066339  0.91948014  1.52114379  0.48154403\n",
      "   0.33343026  1.11055627  0.11539775  0.62084175 -2.63402824  0.02794793\n",
      "  -0.84339956 -0.97747961  0.09110719 -0.20567696  1.71892506  1.67845508\n",
      "   0.90185272  1.99567695  0.11667523 -1.81447039 -1.22146793  0.5194805\n",
      "   0.12508652  0.07762049 -0.08136338 -1.94503928]] \n",
      "\n",
      " [[ 0.43257375  0.44476801  0.6685437  ... -1.40988153  0.06646822\n",
      "  -0.6321507 ]\n",
      " [-0.82170585 -0.46275756  0.31724331 ... -0.43159033 -0.33157361\n",
      "   0.08933486]\n",
      " [ 2.24209067  0.77338148 -0.26812163 ...  0.79920769 -1.64739253\n",
      "   0.83324845]\n",
      " ...\n",
      " [-1.03020448 -0.83923858  1.41237345 ... -0.05475256 -1.57086015\n",
      "   0.1743059 ]\n",
      " [ 0.17965055 -0.69085546 -0.1997973  ...  1.47450262  0.02072746\n",
      "   0.90575264]\n",
      " [-0.22662216 -0.65030077 -0.18791977 ... -0.87858543 -0.66768484\n",
      "   0.33816079]] \n",
      "\n",
      " [[-1.29577793e+00]\n",
      " [-8.41353806e-01]\n",
      " [-3.69183913e-01]\n",
      " [-1.21292848e+00]\n",
      " [-5.79403184e-01]\n",
      " [ 9.42203584e-01]\n",
      " [-1.00688444e-01]\n",
      " [-2.13992158e-01]\n",
      " [-2.17340526e-01]\n",
      " [ 1.45780457e+00]\n",
      " [-1.07803646e+00]\n",
      " [-1.13288775e+00]\n",
      " [-6.11807019e-01]\n",
      " [-1.23945140e+00]\n",
      " [ 8.10380940e-01]\n",
      " [ 8.11168450e-01]\n",
      " [-6.78521240e-01]\n",
      " [ 1.76381276e-01]\n",
      " [ 3.56350229e-01]\n",
      " [ 9.16566915e-03]\n",
      " [-1.71283100e+00]\n",
      " [ 1.55981734e+00]\n",
      " [-7.89603098e-01]\n",
      " [-1.20628381e+00]\n",
      " [-2.93128368e+00]\n",
      " [ 1.57001373e+00]\n",
      " [ 4.54985593e-02]\n",
      " [-4.94276119e-01]\n",
      " [ 5.63323207e-01]\n",
      " [-1.13853788e+00]\n",
      " [ 5.82867985e-01]\n",
      " [ 4.48309586e-01]\n",
      " [-4.98356471e-01]\n",
      " [-7.18829528e-01]\n",
      " [-7.53129977e-01]\n",
      " [-6.85800367e-01]\n",
      " [ 1.17620580e+00]\n",
      " [ 1.25415177e+00]\n",
      " [ 7.43413067e-01]\n",
      " [-1.16046400e+00]\n",
      " [-8.94696847e-02]\n",
      " [-9.83125189e-01]\n",
      " [-1.29332490e-01]\n",
      " [ 1.21050893e-01]\n",
      " [ 1.14204819e+00]\n",
      " [ 8.23848294e-01]\n",
      " [ 5.60751663e-01]\n",
      " [-3.43982152e-01]\n",
      " [ 1.87000214e+00]\n",
      " [-4.79567673e-01]\n",
      " [ 2.44459778e-01]\n",
      " [ 1.72983169e-01]\n",
      " [-6.76199781e-01]\n",
      " [ 4.46034350e-01]\n",
      " [ 4.64189186e-01]\n",
      " [-9.49686494e-01]\n",
      " [ 6.13612097e-01]\n",
      " [ 1.58109401e+00]\n",
      " [ 4.17625180e-01]\n",
      " [-5.11069597e-01]\n",
      " [ 1.83911790e+00]\n",
      " [ 7.70768830e-01]\n",
      " [ 8.46482426e-01]\n",
      " [ 6.55356330e-01]\n",
      " [-9.73507992e-02]\n",
      " [-1.18354322e+00]\n",
      " [-4.55214452e-01]\n",
      " [-3.37935691e-01]\n",
      " [-6.14759989e-02]\n",
      " [-9.81280873e-03]\n",
      " [ 5.95809706e-01]\n",
      " [ 1.40206648e-01]\n",
      " [-9.25819616e-01]\n",
      " [-6.97179611e-01]\n",
      " [-1.21357192e-02]\n",
      " [-1.06563027e+00]\n",
      " [-1.52163555e+00]\n",
      " [-8.94112715e-01]\n",
      " [-6.20429856e-01]\n",
      " [ 2.00600755e+00]\n",
      " [-8.95182402e-01]\n",
      " [-2.03835490e-01]\n",
      " [ 4.07256377e-02]\n",
      " [ 5.77010464e-01]\n",
      " [ 4.52517538e-01]\n",
      " [ 5.03170859e-01]\n",
      " [-5.86888359e-02]\n",
      " [ 2.68677460e-01]\n",
      " [-8.27435521e-01]\n",
      " [ 1.96813944e+00]\n",
      " [ 6.87937267e-01]\n",
      " [-7.89626489e-01]\n",
      " [ 1.05311144e-03]\n",
      " [ 7.46454893e-02]\n",
      " [ 1.64444840e-02]\n",
      " [-2.37484073e-01]\n",
      " [-2.90012607e-01]\n",
      " [-1.49133208e+00]\n",
      " [-2.43048902e+00]\n",
      " [-7.99841800e-01]]\n"
     ]
    }
   ],
   "source": [
    "w1 = generate_wt(2, 100)\n",
    "w2 = generate_wt(100, 100)\n",
    "w3 = generate_wt(100, 1)\n",
    "print(w1, \"\\n\\n\", w2, \"\\n\\n\", w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1 ======== acc: 99.6809479262181\n",
      "epochs: 2 ======== acc: 99.87225212794975\n",
      "epochs: 3 ======== acc: 99.88703897055116\n",
      "epochs: 4 ======== acc: 99.89480344019319\n",
      "epochs: 5 ======== acc: 99.90014005178082\n",
      "epochs: 6 ======== acc: 99.9044996170898\n",
      "epochs: 7 ======== acc: 99.90837696125635\n",
      "epochs: 8 ======== acc: 99.91194911129048\n",
      "epochs: 9 ======== acc: 99.91528820733805\n",
      "epochs: 10 ======== acc: 99.91843171148338\n",
      "epochs: 11 ======== acc: 99.92140446100706\n",
      "epochs: 12 ======== acc: 99.92422530489122\n",
      "epochs: 13 ======== acc: 99.92690915366609\n",
      "epochs: 14 ======== acc: 99.92946780825676\n",
      "epochs: 15 ======== acc: 99.93191052194854\n",
      "epochs: 16 ======== acc: 99.93424451759252\n",
      "epochs: 17 ======== acc: 99.93647548089788\n",
      "epochs: 18 ======== acc: 99.93860800750488\n",
      "epochs: 19 ======== acc: 99.94064598169493\n",
      "epochs: 20 ======== acc: 99.94259287465312\n",
      "epochs: 21 ======== acc: 99.94445196078962\n",
      "epochs: 22 ======== acc: 99.94622645902379\n",
      "epochs: 23 ======== acc: 99.94791961132692\n",
      "epochs: 24 ======== acc: 99.94953471322184\n",
      "epochs: 25 ======== acc: 99.95107511087772\n",
      "epochs: 26 ======== acc: 99.95254417770602\n",
      "epochs: 27 ======== acc: 99.95394528077242\n",
      "epochs: 28 ======== acc: 99.95528174454756\n",
      "epochs: 29 ======== acc: 99.95655681696623\n",
      "epochs: 30 ======== acc: 99.95777364067106\n",
      "epochs: 31 ======== acc: 99.95893523074841\n",
      "epochs: 32 ======== acc: 99.9600444591803\n",
      "epochs: 33 ======== acc: 99.96110404555716\n",
      "epochs: 34 ======== acc: 99.96211655322128\n",
      "epochs: 35 ======== acc: 99.96308438985312\n",
      "epochs: 36 ======== acc: 99.96400981149733\n",
      "epochs: 37 ======== acc: 99.96489492909656\n",
      "epochs: 38 ======== acc: 99.96574171671729\n",
      "epochs: 39 ======== acc: 99.96655202078736\n",
      "epochs: 40 ======== acc: 99.96732756979986\n",
      "epochs: 41 ======== acc: 99.96806998406382\n",
      "epochs: 42 ======== acc: 99.9687807851922\n",
      "epochs: 43 ======== acc: 99.96946140511032\n",
      "epochs: 44 ======== acc: 99.9701131944442\n",
      "epochs: 45 ======== acc: 99.97073743020664\n",
      "epochs: 46 ======== acc: 99.97133532274617\n",
      "epochs: 47 ======== acc: 99.97190802195632\n",
      "epochs: 48 ======== acc: 99.97245662276846\n",
      "epochs: 49 ======== acc: 99.9729821699668\n",
      "epochs: 50 ======== acc: 99.97348566237581\n"
     ]
    }
   ],
   "source": [
    "acc, losss, w1, w2, w3 = train(x_train, y_train, w1, w2, w3, 0.1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = predict(x_test, w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0016656023644645115"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Average Error :\")\n",
    "np.sum(y_hat - y_test) / 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value :  [0.03731237]  | Actual value :  [0.01490764]\n",
      "Predicted Value :  [0.0682571]  | Actual value :  [0.07139891]\n",
      "Predicted Value :  [0.20958651]  | Actual value :  [0.20763597]\n",
      "Predicted Value :  [0.47299385]  | Actual value :  [0.46110878]\n",
      "Predicted Value :  [0.65438314]  | Actual value :  [0.64144799]\n",
      "Predicted Value :  [0.14253393]  | Actual value :  [0.15396557]\n",
      "Predicted Value :  [0.66765446]  | Actual value :  [0.65651419]\n",
      "Predicted Value :  [0.05122463]  | Actual value :  [0.03900514]\n",
      "Predicted Value :  [0.00223973]  | Actual value :  [0.00074239]\n",
      "Predicted Value :  [0.00699735]  | Actual value :  [0.00092263]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print (\"Predicted Value : \" , y_hat[i], \" | Actual value : \", y_test[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b295c30d0c067a9418a4b067b0cfef7f3b1fb611fd6e026430322d33d3e99eef"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('deep_learning_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
